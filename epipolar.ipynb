{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.2'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from single_camera_calibrator import *\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_left_image = cv2.imread('./images/left/left03.jpg')  \n",
    "original_right_image = cv2.imread('./images/right/right03.jpg')\n",
    "undistorted_left_image = cv2.imread('./images/undistorted_left/left03.jpg')  \n",
    "undistorted_right_image = cv2.imread('./images/undistorted_right/right03.jpg')\n",
    "rectified_left_image = cv2.imread('./images/rectify_left/left03.jpg')  \n",
    "rectified_right_image = cv2.imread('./images/rectify_right/right03.jpg')"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Undistortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.subplot(3,2,1)\n",
    "plt.imshow(original_left_image)\n",
    "plt.title('original left image')\n",
    "plt.subplot(3,2,2)\n",
    "plt.imshow(original_right_image)\n",
    "plt.title('original right image')\n",
    "plt.subplot(3,2,3)\n",
    "plt.imshow(undistorted_left_image)\n",
    "plt.title('left image after undistortion')\n",
    "plt.subplot(3,2,4)\n",
    "plt.imshow(original_right_image)\n",
    "plt.title('right image undistortion')\n",
    "plt.subplot(3,2,5)\n",
    "plt.imshow(left_image)\n",
    "plt.title('left image after rectify')\n",
    "plt.subplot(3,2,6)\n",
    "plt.imshow(right_image)\n",
    "plt.title('right image after rectify')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "gray_left_image = cv2.cvtColor(left_image, cv2.COLOR_BGR2GRAY)\n",
    "gray_right_image = cv2.cvtColor(right_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(gray_left_image,None)\n",
    "kp2, des2 = sift.detectAndCompute(gray_right_image,None)\n",
    "\n",
    "featured_left_image = cv2.drawKeypoints(left_image,kp1,left_image,color=(255,0,255))\n",
    "featured_right_image = cv2.drawKeypoints(right_image,kp2,right_image,color=(255,0,255))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(featured_left_image)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(featured_right_image)\n",
    "plt.show()\n",
    "\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)\n",
    "\n",
    "# FLANNBasedMatcher\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "good_matches = []\n",
    "left_image_points = []\n",
    "right_image_points = []\n",
    "\n",
    "# ratio test as per Lowe's paper\n",
    "for i,(m,n) in enumerate(matches):\n",
    "\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        good_matches.append(m)\n",
    "        right_image_points.append(kp2[m.trainIdx].pt)\n",
    "        left_image_points.append(kp1[m.queryIdx].pt)\n",
    "        \n",
    "matched_image = cv2.drawMatches(left_image, kp1, right_image, kp2, good_matches, None, flags=2)\n",
    "\n",
    "plt.imshow(matched_image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "left_image_points = np.int32(left_image_points)\n",
    "right_image_points = np.int32(right_image_points)\n",
    "F, mask = cv2.findFundamentalMat(\n",
    "    points1=left_image_points,\n",
    "    points2=right_image_points,\n",
    "    method=cv2.FM_LMEDS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select only inlier points\n",
    "left_image_points = left_image_points[mask.ravel()==1]\n",
    "right_image_points = right_image_points[mask.ravel()==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawlines(image,lines,points):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    r,c = image.shape[:2]\n",
    "\n",
    "    for r,point in zip(lines,points):\n",
    "        color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        image = cv2.line(image, (x0,y0), (x1,y1), color,1)\n",
    "        image = cv2.circle(image,tuple(point),5,color,-1)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find epilines corresponding to points in right image (second image) and\n",
    "# drawing its lines on left image\n",
    "lines1 = cv2.computeCorrespondEpilines(right_image_points.reshape(-1,1,2), 2,F)\n",
    "lines1 = lines1.reshape(-1,3)\n",
    "\n",
    "epipolar_left_image = drawlines(\n",
    "    left_image,\n",
    "    lines1,\n",
    "    left_image_points,\n",
    ")\n",
    "\n",
    "\n",
    "# Find epilines corresponding to points in left image (first image) and\n",
    "# drawing its lines on right image\n",
    "lines2 = cv2.computeCorrespondEpilines(left_image_points.reshape(-1,1,2), 1,F)\n",
    "lines2 = lines2.reshape(-1,3)\n",
    "\n",
    "epipolar_right_image = drawlines(\n",
    "    right_image,\n",
    "    lines2,\n",
    "    right_image_points,\n",
    ")\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(epipolar_left_image)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(epipolar_right_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
